{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "372Zu6Ast0yv",
        "outputId": "bf8a0b33-f534-4649-9638-26f83c13eb38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-YOLOv4'...\n",
            "remote: Enumerating objects: 1049, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 1049 (delta 2), reused 0 (delta 0), pack-reused 1043\u001b[K\n",
            "Receiving objects: 100% (1049/1049), 2.39 MiB | 8.68 MiB/s, done.\n",
            "Resolving deltas: 100% (644/644), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Tianxiaomo/pytorch-YOLOv4.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rINKktjZuVVj",
        "outputId": "29357ced-b41d-4c18-af5b-b0911968fd48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "pytorch-YOLOv4\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"pytorch-YOLOv4\")"
      ],
      "metadata": {
        "id": "_U93WsWLuplQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tool.darknet2pytorch import Darknet\n",
        "import torch\n",
        "import cv2"
      ],
      "metadata": {
        "id": "22I3jcgh6Hvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = Darknet('cfg/yolov4-tiny.cfg')\n",
        "m.load_weights('yolov4-tiny.weights')"
      ],
      "metadata": {
        "id": "VAtShnkFLr2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4JxSdqNLXdO",
        "outputId": "a95a3761-9145-4133-8ff2-8bee5d2d0137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread('data/dog.jpg')\n",
        "sized = cv2.resize(img, (m.width, m.height))\n",
        "sized = cv2.cvtColor(sized, cv2.COLOR_BGR2RGB)\n",
        "img = torch.from_numpy(sized.transpose(2, 0, 1)).float().div(255.0).unsqueeze(0)"
      ],
      "metadata": {
        "id": "wFh8adeqYi5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_block = m.models[0]\n",
        "first_block\n",
        "second_block = m.models[1]\n",
        "second_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJnH6dVOYlcg",
        "outputId": "0c68bbb9-496a-437f-d90f-0a848269d611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (leaky2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_file(path, data):\n",
        "    print (f\"Writing data with shape {data.shape} to file {path}\")\n",
        "    with open(path, \"wb\") as f:\n",
        "        data.tofile(f)"
      ],
      "metadata": {
        "id": "jeSHex-IZmD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fuse_conv_and_bn(conv, bn):\n",
        "#\n",
        "# init\n",
        "    fusedconv = torch.nn.Conv2d(\n",
        "    conv.in_channels,\n",
        "    conv.out_channels,\n",
        "    kernel_size=conv.kernel_size,\n",
        "    stride=conv.stride,\n",
        "    padding=conv.padding,\n",
        "    bias=True\n",
        "    )\n",
        "    #\n",
        "    # prepare filters\n",
        "    w_conv = conv.weight.clone().view(conv.out_channels, -1)\n",
        "    w_bn = torch.diag(bn.weight.div(torch.sqrt(bn.eps+bn.running_var)))\n",
        "    #fusedconv.weight.copy_( torch.mm(w_bn, w_conv).view(fusedconv.weight.size()) )\n",
        "    new_weight = torch.mm(w_bn, w_conv).view(fusedconv.weight.size())\n",
        "    fusedconv.weight = torch.nn.Parameter(new_weight)\n",
        "    #\n",
        "    # prepare spatial bias\n",
        "    if conv.bias is not None:\n",
        "        b_conv = conv.bias\n",
        "    else:\n",
        "        b_conv = torch.zeros( conv.weight.size(0) )\n",
        "    b_bn = bn.bias - bn.weight.mul(bn.running_mean).div(torch.sqrt(bn.running_var + bn.eps))\n",
        "    #fusedconv.bias.copy_( torch.matmul(w_bn, b_conv) + b_bn )\n",
        "    new_bias = torch.matmul(w_bn, b_conv) + b_bn\n",
        "    fusedconv.bias = torch.nn.Parameter(new_bias)\n",
        "    #\n",
        "    # we're done\n",
        "    return fusedconv"
      ],
      "metadata": {
        "id": "FWGWcmpGNtI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer1 = first_block[0]\n",
        "bn1 = first_block[1]\n",
        "leaky1 = first_block[2]\n",
        "bn1.bias\n",
        "conv_layer2 = second_block[0]\n",
        "bn2 = second_block[1]\n",
        "leaky2 = second_block[2]"
      ],
      "metadata": {
        "id": "esqsZxIJELNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_weight_name = './bin/batchnorm_weight.bin'\n",
        "batchnorm_layer = first_block[1]\n",
        "save_to_file(batchnorm_weight_name, batchnorm_layer.weight.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_mmXR5XdmNK",
        "outputId": "d62c764d-1445-4b94-9836-ac19a70666b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32,) to file ./bin/batchnorm_weight.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_bias_name = './bin/batchnorm_bias.bin'\n",
        "batchnorm_layer = first_block[1]\n",
        "save_to_file(batchnorm_bias_name, batchnorm_layer.bias.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b82ZcHT2Op4f",
        "outputId": "a598ddb9-35c0-4611-a65d-6ca3e2d7cdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32,) to file ./bin/batchnorm_bias.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = bn1.eps\n",
        "bn_factor    = torch.div(bn1.weight,torch.sqrt(bn1.running_var+EPS)).view(-1,1,1,1)\n",
        "fused_weight = torch.mul(conv_layer1.weight, bn_factor)\n",
        "fused_bias   = bn1.bias - torch.div(torch.mul(bn1.weight,bn1.running_mean),torch.sqrt(bn1.running_var+EPS))"
      ],
      "metadata": {
        "id": "afnAm65IUGGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fused_bias_name = '../fused_bias.bin'\n",
        "bias_l1 = fused_bias\n",
        "save_to_file(fused_bias_name, bias_l1.data.numpy())\n",
        "\n",
        "fused_weight_name = '../fused_weight.bin'\n",
        "weight_l1 = fused_weight\n",
        "save_to_file(fused_weight_name, weight_l1.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7NqbEe9WdNg",
        "outputId": "ae18f1d9-552f-40f3-9053-338363425e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32,) to file ../fused_bias.bin\n",
            "Writing data with shape (32, 3, 3, 3) to file ../fused_weight.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fused_conv = fuse_conv_and_bn(conv_layer1, bn1) \n",
        "fused_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQc2KCrsImZ6",
        "outputId": "0bfc9e4e-4b77-4ab4-d4a5-d749cb4672d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer_bias_name = '../conv_bias.bin'\n",
        "bias_l1 = fused_conv.bias\n",
        "save_to_file(conv_layer_bias_name, bias_l1.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_dDBF-zRFuP",
        "outputId": "e7c01888-2a4d-4572-a675-ad9e9a956820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32,) to file ../conv_bias.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer_mod_wts_name = '../conv_weight_bn.bin'\n",
        "conv_l1_wts_bn = fused_conv.weight\n",
        "save_to_file(conv_layer_mod_wts_name, conv_l1_wts_bn.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjnXOYM2XxM6",
        "outputId": "419fc136-ba3e-4a33-9ac7-e60f2b39d02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32, 3, 3, 3) to file ../conv_weight_bn.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Original output\n",
        "conv_layer = first_block[0]\n",
        "conv_output = conv_layer(img)\n",
        "batchnorm_layer = first_block[1]\n",
        "batchnorm_output = batchnorm_layer(conv_output)"
      ],
      "metadata": {
        "id": "kkkujkRfrnXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fused conv output\n",
        "fused_output = fused_conv(img)"
      ],
      "metadata": {
        "id": "qrUbn3RQtMyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = torch.nn.Sequential(conv_layer1,bn1)\n",
        "y1 = net.forward(img)\n",
        "y2 = fused_conv.forward(img)\n",
        "d = (y1 - y2).norm().div(y1.norm()).item()\n",
        "print(\"error: %.8f\" % d)"
      ],
      "metadata": {
        "id": "BFSdl0w0uS5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ba82ad-6aeb-47a8-b7e1-f8fc8bfc7213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: 0.19199745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second Layer Parameters Extraction**"
      ],
      "metadata": {
        "id": "LyfwMFJFd87o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_block = m.models[1]\n",
        "second_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOFO8RZjeGzm",
        "outputId": "8e4e2830-d4fc-4860-bab5-4e9d73819f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (leaky2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer2 = second_block[0]\n",
        "bn2 = second_block[1]\n",
        "leaky2 = second_block[2]"
      ],
      "metadata": {
        "id": "V-NLMqEIeQN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer_weight_name2 = './bin/conv_weight2.bin'\n",
        "save_to_file(conv_layer_weight_name2, conv_layer2.weight.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YjUD2KYekPx",
        "outputId": "fbda3770-e762-4d16-f3de-95f7cc25f228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64, 32, 3, 3) to file ./bin/conv_weight2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output of first layer is input to second"
      ],
      "metadata": {
        "id": "2HsCP5hDgKb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out1_conv = conv_layer1(img)\n",
        "out1_batch = bn1(out1_conv)\n",
        "output_layer1 = leaky1(out1_batch)"
      ],
      "metadata": {
        "id": "cmX3ChVKgP6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write the array to a binary file\n",
        "input_to_second_name = './bin/conv_input2.bin'\n",
        "save_to_file(input_to_second_name, output_layer1[0].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87WiDfDwhE3j",
        "outputId": "6c50616f-cc1e-4ace-cd68-b0597ab96a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (32, 208, 208) to file ./bin/conv_input2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_weight_name2 = './bin/batchnorm_weight2.bin'\n",
        "\n",
        "save_to_file(batchnorm_weight_name2, bn2.weight.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3WGb5wMiHU4",
        "outputId": "66343f34-0ede-4cd6-add8-8219c43e7751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64,) to file ./bin/batchnorm_weight2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_bias_name2 = './bin/batchnorm_bias2.bin'\n",
        "\n",
        "save_to_file(batchnorm_bias_name2, bn2.bias.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBEal6bZigct",
        "outputId": "63674276-7e9a-496b-a66b-d39d9efcfdb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64,) to file ./bin/batchnorm_bias2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_output2 = conv_layer2(output_layer1)\n",
        "batchnorm_output2 = bn2(conv_output2)\n",
        "output_layer2 = leaky2(batchnorm_output2)"
      ],
      "metadata": {
        "id": "nNU21RjHizXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_layer_output_name2 = './bin/conv_output2.bin'\n",
        "\n",
        "save_to_file(conv_layer_output_name2, conv_output2[0].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVqxvKy8jlTS",
        "outputId": "1c01eb9e-8ae8-4829-ed0a-62a2401ff1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64, 104, 104) to file ./bin/conv_output2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batchnorm_layer_output_name2 = './bin/batchnorm_output2.bin'\n",
        "\n",
        "save_to_file(batchnorm_layer_output_name2, batchnorm_output2[0].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVo8oO84j_Xt",
        "outputId": "4c93a14e-6517-4678-812b-529581837d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64, 104, 104) to file ./bin/batchnorm_output2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu_layer_output_name2 = './bin/relu_output2.bin'\n",
        "\n",
        "save_to_file(relu_layer_output_name2, output_layer2[0].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM5tJg1ukK-x",
        "outputId": "c28edbec-6e0c-4798-f80c-e342dc7aeee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data with shape (64, 104, 104) to file ./bin/relu_output2.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRYING OUT FUSING FROM SIBI"
      ],
      "metadata": {
        "id": "ZID7tYD7evfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "write_layer_outputs_to_file = True\n",
        "write_layer_params_to_file  = True\n",
        "\n",
        "features = {}\n",
        "def get_features(name):\n",
        "  def hook(model, input, output):\n",
        "    features[name] = output.detach()\n",
        "  return hook\n",
        "\n",
        "model = m.models[0] #Change the model numbers here. This is the first layer now\n",
        "model.eval()\n",
        "print(model)\n",
        "\n",
        "inp = torch.ones(1, 3, 736, 1280)\n",
        "\n",
        "raw_layers = []\n",
        "for layer in model.named_modules():\n",
        "  raw_layers.append(layer[0])\n",
        "\n",
        "leaf_layers = []\n",
        "for i in range(1, len(raw_layers)-1):\n",
        "  curr_layer = raw_layers[i]\n",
        "  next_layer = raw_layers[i+1]\n",
        "  if(next_layer[:len(curr_layer)+1] != curr_layer + \".\"):\n",
        "    leaf_layers.append(curr_layer)\n",
        "leaf_layers.append(next_layer)\n",
        "\n",
        "layers = []\n",
        "for i in range(len(leaf_layers)):\n",
        "  layers.append(re.sub(r\"\\.(\\d)\",r\"[\\1]\",leaf_layers[i]))\n",
        "\n",
        "for i in range(len(layers)):\n",
        "  layer = layers[i]\n",
        "  layer_hook = \"model.\" + layer + \".register_forward_hook(get_features('\" + layer + \"'))\"\n",
        "  exec(layer_hook)\n",
        "\n",
        "# Run inference\n",
        "outp = model(inp)\n",
        "\n",
        "EPS = 10 ** -5 # constant\n",
        "\n",
        "if(write_layer_outputs_to_file):\n",
        "  # Write layer outputs\n",
        "  for i in range(len(layers)):\n",
        "    layer = layers[i]\n",
        "    if(layer in features.keys()):\n",
        "      layer_name = layer.replace(\"].\",\"_\")\n",
        "      layer_name = layer_name.replace(\"[\", \"_\")\n",
        "      layer_name = layer_name.replace(\"]\", \"\")\n",
        "      filename = \"../\" +  layer_name + \".bin\"\n",
        "      with open(filename,\"wb\") as f:\n",
        "        features[layer].cpu().numpy().tofile(f)\n",
        "      print(\"Layer \" + str(i) + \" feature map printed to \" + filename)\n",
        "\n",
        "if(write_layer_params_to_file):\n",
        "  # Write layer params\n",
        "  for i in range(len(layers)):\n",
        "    layer = layers[i]\n",
        "    if('conv' in layer or 'downsample[0]' in layer):\n",
        "      conv_layer_name = layer.replace(\"].\",\"_\")\n",
        "      conv_layer_name = conv_layer_name.replace(\"[\", \"_\")\n",
        "      conv_layer_name = conv_layer_name.replace(\"]\", \"\")\n",
        "      \n",
        "      conv_param_name = layer.replace(\"[\",\".\")\n",
        "      conv_param_name = conv_param_name.replace(\"]\",\"\")\n",
        "      \n",
        "      conv_weight = model.state_dict()[conv_param_name+'.weight']\n",
        "\n",
        "    if('bn' in layer or 'downsample[1]' in layer):\n",
        "      bn_layer_name = layer.replace(\"].\",\"_\")\n",
        "      bn_layer_name = bn_layer_name.replace(\"[\", \"_\")\n",
        "      bn_layer_name = bn_layer_name.replace(\"]\", \"\")\n",
        "      \n",
        "      bn_param_name = layer.replace(\"[\",\".\")\n",
        "      bn_param_name = bn_param_name.replace(\"]\",\"\")\n",
        "      \n",
        "      bn_weight = model.state_dict()[bn_param_name+'.weight']\n",
        "      bn_bias   = model.state_dict()[bn_param_name+'.bias']\n",
        "      bn_mean   = model.state_dict()[bn_param_name+'.running_mean']\n",
        "      bn_var    = model.state_dict()[bn_param_name+'.running_var']\n",
        "\n",
        "      bn_factor    = torch.div(bn_weight,torch.sqrt(bn_var+EPS)).view(-1,1,1,1)\n",
        "      fused_weight = torch.mul(conv_weight, bn_factor)\n",
        "      fused_bias   = bn_bias - torch.div(torch.mul(bn_weight,bn_mean),torch.sqrt(bn_var+EPS))\n",
        "\n",
        "      if('downsample' in bn_layer_name):\n",
        "        layer_number = '0'\n",
        "        layer_prefix = bn_layer_name[0:bn_layer_name.find('downsample')]\n",
        "      else:\n",
        "        layer_number = conv_layer_name[-1]\n",
        "        layer_prefix = bn_layer_name[0:bn_layer_name.find('bn')]\n",
        "      \n",
        "      weights_filename = \"../fused_\" + layer_prefix + \"conv\" + layer_number + \"_bn\" + layer_number + \"_weights.bin\" #This gives the bin for weights\n",
        "      bias_filename    = \"../fused_\" + layer_prefix + \"conv\" + layer_number + \"_bn\" + layer_number + \"_bias.bin\" #This gives the bin for bias\n",
        "\n",
        "      with open(weights_filename, \"wb\") as f:\n",
        "        fused_weight.detach().numpy().tofile(f)\n",
        "      print(\"Fused weights of \" + layer_prefix + layer_number + \" printed to file \" + weights_filename)\n",
        "\n",
        "      with open(bias_filename, \"wb\") as f:\n",
        "        fused_bias.detach().numpy().tofile(f)\n",
        "      print(\"Fused biases of \" + layer_prefix + layer_number + \" printed to file \" + bias_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsTTzotLez_d",
        "outputId": "1d0024f7-423f-496e-98a4-f8cafcee4356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (leaky1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
            ")\n",
            "Layer 0 feature map printed to ../conv1.bin\n",
            "Layer 1 feature map printed to ../bn1.bin\n",
            "Layer 2 feature map printed to ../leaky1.bin\n",
            "Fused weights of 1 printed to file ../fused_conv1_bn1_weights.bin\n",
            "Fused biases of 1 printed to file ../fused_conv1_bn1_bias.bin\n"
          ]
        }
      ]
    }
  ]
}